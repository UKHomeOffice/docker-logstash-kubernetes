filter {
  if "journald" in [tags] {
    # check if message looks like json and try to decode it
    if [message] =~ /^\{.*\}$/ {
      json {
        source => "message"
        target => "message_json"
        remove_field => [ "message" ]
      }
    }

    # Rename fields which start with a '_'
    mutate {
      rename => { "_selinux_context" => "selinux_context" }
      rename => { "_systemd_cgroup" => "systemd_cgroup" }
      rename => { "_systemd_slice" => "systemd_clice" }
      rename => { "_systemd_unit" => "systemd_unit" }
      rename => { "_transport" => "transport" }
      rename => { "_cap_effective" => "cap_effective" }
      rename => { "_cmdline" => "cmdline" }
      rename => { "_comm" => "comm" }
      rename => { "_exe" => "exe" }
      rename => { "_gid" => "gid" }
      rename => { "_hostname" => "hostname" }
      rename => { "_machine_id" => "machine_id" }
      rename => { "_pid" => "pid" }
      rename => { "_uid" => "uid" }
    }

    # Remove messages bigger than ~20kB in size to stop LS sending bulks which are too big.
    # This calculation is based on default ES max bulk size of 100MB and LS flush_size of 5000.
    truncate {
      length_bytes => 20000
    }
  }
}

output {
  if "journald" in [tags] {
    elasticsearch {
      index => "journald-%ELASTICSEARCH_INDEX_SUFFIX%%{+YYYY.MM.dd}"
      document_type => "%{transport}"
      hosts => [ "%ELASTICSEARCH_HOST%" ]
      validate_after_inactivity => 60
      idle_flush_time => %ELASTICSEARCH_IDLE_FLUSH_TIME%
      flush_size => %ELASTICSEARCH_FLUSH_SIZE%
    }
  }
}
